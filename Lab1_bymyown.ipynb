{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/connectome/ahhyun724/.conda/envs/3D_CNN_woPip/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "\n",
    "# dataset and dataloader\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform = transform)\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform = transform)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "trainloader = DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "testloader = DataLoader(testset, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n",
      "data shape:  torch.Size([60000, 28, 28])\n",
      "target shape:  torch.Size([60000])\n",
      "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])\n",
      "torch.Size([28, 28])\n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54,\n",
      "         227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60, 224,\n",
      "         252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252, 252,\n",
      "         252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253, 253,\n",
      "         190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252, 179,\n",
      "          12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,  84,\n",
      "           0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,  28,\n",
      "           0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,   0,\n",
      "           0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,   0,\n",
      "           0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85, 178,\n",
      "         225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252, 252,\n",
      "         252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252, 233,\n",
      "         145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,  37,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
      "       dtype=torch.uint8)\n",
      "torch.Size([28])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# 위의 형태로부터 dataset 이 어떻게 생겼는지 확인해야 -> CustomDataset 을 만들 수 있음\n",
    "print(trainloader.dataset)\n",
    "print(\"data shape: \", trainloader.dataset.data.shape)\n",
    "print(\"target shape: \", trainloader.dataset.targets.shape)\n",
    "print(trainloader.dataset.targets[:10])\n",
    "print(trainloader.dataset.data[1].shape)\n",
    "print(trainloader.dataset.data[1])\n",
    "print(trainloader.dataset.data[1][1].shape)\n",
    "print(trainloader.dataset.data[1][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(trainloader.dataset.data[0].shape) #first image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(trainloader.dataset.data[i], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(trainloader.dataset.targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n",
      "60000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(trainloader.dataset.data.shape)\n",
    "print(trainloader.dataset.targets.shape)\n",
    "print(len(trainloader.dataset.data))\n",
    "print(len(trainloader.dataset.targets))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([28, 28])\n",
      "torch.Size([])\n",
      "torch.float32\n",
      "torch.uint8\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "trainloader.dataset[0] #tuple\n",
    "trainloader.dataset[0][0] #first image\n",
    "trainloader.dataset[0][1] #first label\n",
    "trainloader.dataset.data[0] #first image\n",
    "trainloader.dataset.targets[0] #first label\n",
    "\n",
    "print(trainloader.dataset[0][0].shape) #first image \"TRANSFORMED\" by dataloader\n",
    "# print(trainloader.dataset[0][1].shape) #first label => int \"TRANSFORMED\" by dataloader\n",
    "print(trainloader.dataset.data[0].shape) #first image \"RAW\"\n",
    "print(trainloader.dataset.targets[0].shape) #first label \"RAW\"\n",
    "\n",
    "print(trainloader.dataset[0][0].dtype) #first image\n",
    "#print(trainloader.dataset[0][1].dtype) #first label => int\n",
    "print(trainloader.dataset.data[0].dtype) #first image\n",
    "print(trainloader.dataset.targets[0].dtype) #first label\n",
    "\n",
    "\n",
    "# first index of the dataset ;  image\n",
    "# [0][0] -> image, first\n",
    "# [0][1] -> label, first\n",
    "# [1][0] -> image, second\n",
    "# [1][1] -> label, second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "# Make CustomDataset to check whether downloading is properly done + collate function\n",
    "    def __init__(self):\n",
    "        x_data = trainloader.dataset.data\n",
    "        y_data = trainloader.dataset.targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def __collate_fn__(self, batch):\n",
    "        return torch.stack(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# below followed copilot\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "    def collate_fn(self, batch):\n",
    "        return torch.stack(batch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from here\n",
    "\n",
    "# import libraries\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "\n",
    "# dataset and dataloader\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform = transform)\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform = transform)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "trainloader = DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "testloader = DataLoader(testset, batch_size = BATCH_SIZE, shuffle = False) \n",
    "# currently no collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,32)\n",
    "        self.fc4 = nn.Linear(32,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(f\"Input shape: {x.shape}\")\n",
    "        x = x.reshape(-1, 28*28)\n",
    "            # -1 은 마지막 차원을 28*28 으로 만들기 위해 나머지는 알아서 차원 결정해줘~\n",
    "        #print(f\"Input shape: {x.shape}\")\n",
    "        #[batch_size, 1, 28, 28] -> [batch_size, 28*28]\n",
    "        # 1: gray scale, 28:height, 28:width\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인 위한 코드\n",
    "model = MyNN()\n",
    "output = model(trainloader.dataset[3][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNN(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiation of MyNN\n",
    "\n",
    "network = MyNN()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train function\n",
    "\n",
    "def train(model, optim, loss_fn, train_loader, epochs, device):\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.0\n",
    "        model.train() # turn the training mode on\n",
    "        for batch in train_loader:\n",
    "            data, target = batch\n",
    "            data, target = data.to(device), target.to(device) # send to GPU\n",
    "\n",
    "            # Compute gradient\n",
    "            optim.zero_grad() # initialize the gradient\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss /= len(train_loader.dataset) # normalize training loss\n",
    "        print(f\"Epoch: {epoch}, Loss: {train_loss/len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.86581327712763e-07\n",
      "Epoch: 1, Loss: 2.50683973199809e-07\n",
      "Epoch: 2, Loss: 2.2094926233021124e-07\n",
      "Epoch: 3, Loss: 2.0060713628848768e-07\n",
      "Epoch: 4, Loss: 1.7660515994314594e-07\n",
      "Epoch: 5, Loss: 1.5803468409100283e-07\n",
      "Epoch: 6, Loss: 1.3687991517585688e-07\n",
      "Epoch: 7, Loss: 1.1886291660498509e-07\n",
      "Epoch: 8, Loss: 1.0440581077695728e-07\n",
      "Epoch: 9, Loss: 9.417443579929439e-08\n"
     ]
    }
   ],
   "source": [
    "# perform actual training\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "#optimizer = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "optimizer = optim.SGD(network.parameters(), lr=0.01, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "trainloader = trainloader\n",
    "EPOCH = 10\n",
    "network.to(device) # send to GPU ; 이거 안 하면 model 이 서로 다른 device 에 있다고 그럼\n",
    "\n",
    "train(network, optimizer, loss_fn, trainloader, EPOCH, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-68-4a8d034a63fc>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-68-4a8d034a63fc>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def test(model,loss_fn, test_loader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad(): #if not, it will consume memory\n",
    "        for batch in test_loader:\n",
    "            data, target = batch\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True) #[batch_size, num_classes], argmax over num_classes\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3D_CNN_woPip_kernel",
   "language": "python",
   "name": "3d_cnn_wopip_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
